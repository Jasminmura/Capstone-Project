{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqqMV2AtOEk_",
        "outputId": "fc8a81a6-74f2-477c-ed87-5939e31e1062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvxhB9ZCOlbD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQrkTj88Orvy",
        "outputId": "c3740b78-9fc7-4e61-cb5c-b79d20193d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Key  Longitude  Latitude\n",
            "0    0   -179.750     -90.0\n",
            "1    1   -160.623     -90.0\n",
            "2    2   -141.496     -90.0\n",
            "3    3   -122.369     -90.0\n",
            "4    4   -103.242     -90.0\n"
          ]
        }
      ],
      "source": [
        "excel_file_path = '/content/data_cord.xlsx'\n",
        "location_mapping = pd.read_excel(excel_file_path, header=None)\n",
        "\n",
        "location_mapping.columns = ['Key', 'Longitude', 'Latitude']\n",
        "print(location_mapping.head())\n",
        "\n",
        "location_mapping.to_csv('/content/labeled_data_cord.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgpklvCcPxl7",
        "outputId": "1d4f6b24-11e3-45b7-a47b-64e7a63691a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   9979980        0        1        2        3        4        5        6  \\\n",
            "0      0.0 -10.9407 -10.9176 -10.7401 -10.6351 -10.6105 -10.6537 -10.7529   \n",
            "1      1.0 -11.4615 -11.4658 -11.2996 -11.1863 -11.1189 -11.0640 -11.0277   \n",
            "2      2.0 -11.6993 -11.7204 -11.5398 -11.4029 -11.3031 -11.2401 -11.2297   \n",
            "3      3.0 -11.8687 -11.8832 -11.7073 -11.5691 -11.4583 -11.3613 -11.3092   \n",
            "4      4.0 -11.9462 -12.0216 -11.8642 -11.7481 -11.6750 -11.6107 -11.5904   \n",
            "\n",
            "         7        8  ...    12968    12969    12970    12971    12972  12973  \\\n",
            "0 -10.8037 -10.8785  ... -18.0806 -18.0993 -18.0993 -18.1180 -18.7721      0   \n",
            "1 -10.9726 -10.9973  ... -17.7401 -17.7584 -17.7584 -17.7768 -18.4185      0   \n",
            "2 -11.2281 -11.2914  ... -18.4289 -18.4480 -18.4480 -18.4670 -19.1337      0   \n",
            "3 -11.2606 -11.2767  ... -18.0342 -18.0528 -18.0528 -18.0715 -18.7239      0   \n",
            "4 -11.5531 -11.5631  ... -18.6457 -18.6649 -18.6649 -18.6842 -19.3587      0   \n",
            "\n",
            "   10507020  11032620  11558220  12083820  \n",
            "0       NaN       NaN       NaN       NaN  \n",
            "1       NaN       NaN       NaN       NaN  \n",
            "2       NaN       NaN       NaN       NaN  \n",
            "3       NaN       NaN       NaN       NaN  \n",
            "4       NaN       NaN       NaN       NaN  \n",
            "\n",
            "[5 rows x 12979 columns]\n"
          ]
        }
      ],
      "source": [
        "csv_directory = '/content'\n",
        "\n",
        "def load_weather_data(param):\n",
        "    weather_data = []\n",
        "    for year in range(2019, 2024):\n",
        "        file_name = f\"{param}_{year}.csv\"\n",
        "        file_path = os.path.join(csv_directory, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            df = pd.read_csv(file_path)\n",
        "            weather_data.append(df)\n",
        "        else:\n",
        "            print(f\"File not found: {file_name}\")\n",
        "    return pd.concat(weather_data, ignore_index=True)\n",
        "\n",
        "temperature_data = load_weather_data('Temperature')\n",
        "wind_speed_data = load_weather_data('Wind')\n",
        "rain_probability_data = load_weather_data('Rain')\n",
        "moisture_data = load_weather_data('Moisture')\n",
        "\n",
        "print(temperature_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kuYLZrVXgp",
        "outputId": "bf5a749c-0610-4176-d07b-7073d54f4302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in temperature_data: Index(['9979980', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
            "       ...\n",
            "       '12968', '12969', '12970', '12971', '12972', '12973', '10507020',\n",
            "       '11032620', '11558220', '12083820'],\n",
            "      dtype='object', length=12979)\n",
            "Columns in location_mapping: Index(['Key', 'Longitude', 'Latitude'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(\"Columns in temperature_data:\", temperature_data.columns)\n",
        "print(\"Columns in location_mapping:\", location_mapping.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGxrDpYYQeRi",
        "outputId": "9195dce4-45cf-4b3d-f170-01c700905f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Key        0        1        2        3        4        5        6  \\\n",
            "0  0.0 -10.9407 -10.9176 -10.7401 -10.6351 -10.6105 -10.6537 -10.7529   \n",
            "1  1.0 -11.4615 -11.4658 -11.2996 -11.1863 -11.1189 -11.0640 -11.0277   \n",
            "2  2.0 -11.6993 -11.7204 -11.5398 -11.4029 -11.3031 -11.2401 -11.2297   \n",
            "3  3.0 -11.8687 -11.8832 -11.7073 -11.5691 -11.4583 -11.3613 -11.3092   \n",
            "4  4.0 -11.9462 -12.0216 -11.8642 -11.7481 -11.6750 -11.6107 -11.5904   \n",
            "\n",
            "         7        8  ...    12970    12971    12972  12973  10507020  \\\n",
            "0 -10.8037 -10.8785  ... -18.0993 -18.1180 -18.7721      0       NaN   \n",
            "1 -10.9726 -10.9973  ... -17.7584 -17.7768 -18.4185      0       NaN   \n",
            "2 -11.2281 -11.2914  ... -18.4480 -18.4670 -19.1337      0       NaN   \n",
            "3 -11.2606 -11.2767  ... -18.0528 -18.0715 -18.7239      0       NaN   \n",
            "4 -11.5531 -11.5631  ... -18.6649 -18.6842 -19.3587      0       NaN   \n",
            "\n",
            "   11032620  11558220  12083820  Longitude  Latitude  \n",
            "0       NaN       NaN       NaN   -179.750     -90.0  \n",
            "1       NaN       NaN       NaN   -160.623     -90.0  \n",
            "2       NaN       NaN       NaN   -141.496     -90.0  \n",
            "3       NaN       NaN       NaN   -122.369     -90.0  \n",
            "4       NaN       NaN       NaN   -103.242     -90.0  \n",
            "\n",
            "[5 rows x 12981 columns]\n"
          ]
        }
      ],
      "source": [
        "location_mapping.columns = ['Key', 'Longitude', 'Latitude']\n",
        "\n",
        "\n",
        "temperature_data.rename(columns={'9979980': 'Key'}, inplace=True)\n",
        "wind_speed_data.rename(columns={'9979980': 'Key'}, inplace=True)\n",
        "rain_probability_data.rename(columns={'9979980': 'Key'}, inplace=True)\n",
        "moisture_data.rename(columns={'9979980': 'Key'}, inplace=True)\n",
        "\n",
        "\n",
        "def merge_with_mapping(weather_data, mapping):\n",
        "    return weather_data.merge(mapping, on='Key')\n",
        "\n",
        "\n",
        "temperature_data = merge_with_mapping(temperature_data, location_mapping)\n",
        "wind_speed_data = merge_with_mapping(wind_speed_data, location_mapping)\n",
        "rain_probability_data = merge_with_mapping(rain_probability_data, location_mapping)\n",
        "moisture_data = merge_with_mapping(moisture_data, location_mapping)\n",
        "\n",
        "\n",
        "print(temperature_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQVTWgs3QfJz",
        "outputId": "2254c378-8b10-4edb-e628-ba11f40f842f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Key         0         1         2         3         4         5         6  \\\n",
            "0  0.0  0.913409  0.911338  0.907702  0.904849  0.900676  0.892140  0.882151   \n",
            "1  1.0  0.889405  0.886420  0.882275  0.879800  0.877581  0.873473  0.869724   \n",
            "2  2.0  0.878445  0.874847  0.871359  0.869957  0.869214  0.865461  0.860590   \n",
            "3  3.0  0.870637  0.867447  0.863747  0.862404  0.862164  0.859947  0.856995   \n",
            "4  4.0  0.867065  0.861156  0.856617  0.854270  0.852320  0.848600  0.844279   \n",
            "\n",
            "          7         8  ...     12970     12971     12972  12973  10507020  \\\n",
            "0  0.879423  0.883933  ...  0.283128  0.283129  0.283128    0.0       NaN   \n",
            "1  0.871748  0.878520  ...  0.295775  0.295773  0.295776    0.0       NaN   \n",
            "2  0.860137  0.865119  ...  0.270192  0.270195  0.270194    0.0       NaN   \n",
            "3  0.858660  0.865788  ...  0.284853  0.284852  0.284852    0.0       NaN   \n",
            "4  0.845369  0.852738  ...  0.262145  0.262145  0.262146    0.0       NaN   \n",
            "\n",
            "   11032620  11558220  12083820  Longitude  Latitude  \n",
            "0       NaN       NaN       NaN   0.000000       0.0  \n",
            "1       NaN       NaN       NaN   0.051223       0.0  \n",
            "2       NaN       NaN       NaN   0.102446       0.0  \n",
            "3       NaN       NaN       NaN   0.153669       0.0  \n",
            "4       NaN       NaN       NaN   0.204892       0.0  \n",
            "\n",
            "[5 rows x 12981 columns]\n"
          ]
        }
      ],
      "source": [
        "scaler_coords = MinMaxScaler()\n",
        "scaler_weather = MinMaxScaler()\n",
        "def normalize_data(df):\n",
        "\n",
        "    df[['Longitude', 'Latitude']] = scaler_coords.fit_transform(df[['Longitude', 'Latitude']])\n",
        "    weather_columns = [col for col in df.columns if col not in ['Key', 'Longitude', 'Latitude'] and not df[col].isnull().all()]\n",
        "    df[weather_columns] = scaler_weather.fit_transform(df[weather_columns])\n",
        "\n",
        "    return df\n",
        "\n",
        "temperature_data = normalize_data(temperature_data)\n",
        "wind_speed_data = normalize_data(wind_speed_data)\n",
        "rain_probability_data = normalize_data(rain_probability_data)\n",
        "moisture_data = normalize_data(moisture_data)\n",
        "\n",
        "\n",
        "print(temperature_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erP1SGogcnRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def combine_csv_files(param, years, csv_directory):\n",
        "    combined_data = []\n",
        "    for year in years:\n",
        "        file_path = os.path.join(csv_directory, f\"{param}_{year}.csv\")\n",
        "        if os.path.exists(file_path):\n",
        "            df = pd.read_csv(file_path)\n",
        "            combined_data.append(df)\n",
        "        else:\n",
        "            print(f\"File not found: {file_path}\")\n",
        "    return pd.concat(combined_data, ignore_index=True)\n",
        "\n",
        "csv_directory = '/content'  \n",
        "years = range(2019, 2024)\n",
        "\n",
        "temperature_data = combine_csv_files('Temperature', years, csv_directory)\n",
        "wind_speed_data = combine_csv_files('Wind', years, csv_directory)\n",
        "rain_probability_data = combine_csv_files('Rain', years, csv_directory)\n",
        "moisture_data = combine_csv_files('Moisture', years, csv_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpI8t3JKcsma"
      },
      "outputs": [],
      "source": [
        "def aggregate_data(data, window=14):\n",
        "    data['Date'] = pd.to_datetime(data['Day'], unit='D', origin=pd.Timestamp('2019-01-01'))\n",
        "    data['Period'] = (data['Day'] // window).astype(int)\n",
        "    aggregated = data.groupby(['Longitude', 'Latitude', 'Period']).mean().reset_index()\n",
        "    return aggregated\n",
        "\n",
        "temperature_data = aggregate_data(temperature_data)\n",
        "wind_speed_data = aggregate_data(wind_speed_data)\n",
        "rain_probability_data = aggregate_data(rain_probability_data)\n",
        "moisture_data = aggregate_data(moisture_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aF7_cPjQh-9",
        "outputId": "9e13c183-f267-440f-9558-bc25decbf9ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-654868f3712b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Normalized_Day'] = scaler_day.fit_transform(days)\n",
            "<ipython-input-19-654868f3712b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Normalized_Day'] = scaler_day.fit_transform(days)\n",
            "<ipython-input-19-654868f3712b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Normalized_Day'] = scaler_day.fit_transform(days)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model for Temperature trained with 5 clusters.\n",
            "Model for Wind Speed trained with 5 clusters.\n",
            "Model for Rain Probability trained with 5 clusters.\n",
            "Model for Moisture trained with 5 clusters.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-654868f3712b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['Normalized_Day'] = scaler_day.fit_transform(days)\n"
          ]
        }
      ],
      "source": [
        "def train_kmeans_with_day(df, n_clusters, output_param):\n",
        "\n",
        "    scaler_day = MinMaxScaler()  \n",
        "    days = np.linspace(1, len(df), len(df)).reshape(-1, 1) \n",
        "    df['Normalized_Day'] = scaler_day.fit_transform(days)\n",
        "    \n",
        "    features = df[['Longitude', 'Latitude']].copy()\n",
        "    features['Day'] = df['Normalized_Day']\n",
        "   \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans.fit(features)\n",
        "    print(f\"Model for {output_param} trained with {n_clusters} clusters.\")\n",
        "    return kmeans, scaler_day\n",
        "\n",
        "temperature_kmeans, temperature_day_scaler = train_kmeans_with_day(temperature_data, 5, 'Temperature')\n",
        "wind_speed_kmeans, wind_day_scaler = train_kmeans_with_day(wind_speed_data, 5, 'Wind Speed')\n",
        "rain_probability_kmeans, rain_day_scaler = train_kmeans_with_day(rain_probability_data, 5, 'Rain Probability')\n",
        "moisture_kmeans, moisture_day_scaler = train_kmeans_with_day(moisture_data, 5, 'Moisture')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhhO3zVQjsm",
        "outputId": "11c9dc8c-dd6f-43e7-bc75-6ae11e9fb992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as temperature.pkl, Scaler saved as temperature_day_scaler.pkl\n",
            "Model saved as wind_speed.pkl, Scaler saved as wind_speed_day_scaler.pkl\n",
            "Model saved as rain_probability.pkl, Scaler saved as rain_probability_day_scaler.pkl\n",
            "Model saved as moisture.pkl, Scaler saved as moisture_day_scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "output_directory = '/content'\n",
        "\n",
        "def save_model_and_scaler(model, scaler, model_filename, scaler_filename):\n",
        "    with open(os.path.join(output_directory, model_filename), 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "    with open(os.path.join(output_directory, scaler_filename), 'wb') as file:\n",
        "        pickle.dump(scaler, file)\n",
        "    print(f\"Model saved as {model_filename}, Scaler saved as {scaler_filename}\")\n",
        "\n",
        "save_model_and_scaler(temperature_kmeans, temperature_day_scaler, 'temperature.pkl', 'temperature_day_scaler.pkl')\n",
        "save_model_and_scaler(wind_speed_kmeans, wind_day_scaler, 'wind_speed.pkl', 'wind_speed_day_scaler.pkl')\n",
        "save_model_and_scaler(rain_probability_kmeans, rain_day_scaler, 'rain_probability.pkl', 'rain_probability_day_scaler.pkl')\n",
        "save_model_and_scaler(moisture_kmeans, moisture_day_scaler, 'moisture.pkl', 'moisture_day_scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71yKpsETc-cW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def analyze_clusters(data, kmeans_model, features):\n",
        "    data['Cluster'] = kmeans_model.predict(data[features])\n",
        "    cluster_summary = data.groupby('Cluster').mean()\n",
        "    return cluster_summary\n",
        "\n",
        "temperature_clusters = analyze_clusters(temperature_data, temperature_kmeans, features)\n",
        "wind_speed_clusters = analyze_clusters(wind_speed_data, wind_speed_kmeans, features)\n",
        "rain_probability_clusters = analyze_clusters(rain_probability_data, rain_probability_kmeans, features)\n",
        "moisture_clusters = analyze_clusters(moisture_data, moisture_kmeans, features)\n",
        "\n",
        "print(\"Temperature Cluster Analysis:\")\n",
        "print(temperature_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb07lLTRdARj"
      },
      "outputs": [],
      "source": [
        "def predict_weather(longitude, latitude, period, weather_values, kmeans_model, cluster_summary):\n",
        "\n",
        "    normalized_coords = scaler_coords.transform([[longitude, latitude]])\n",
        "    normalized_period = scaler_day.transform([[period]])\n",
        "    normalized_weather = scaler_weather.transform([weather_values])\n",
        "\n",
        "    input_features = np.hstack((normalized_coords, normalized_period, normalized_weather))\n",
        "\n",
        "    cluster = kmeans_model.predict(input_features)[0]\n",
        "\n",
        "    cluster_info = cluster_summary.loc[cluster]\n",
        "\n",
        "    return {\n",
        "        'Cluster': cluster,\n",
        "        'Cluster Characteristics': cluster_info.to_dict(),\n",
        "    }\n",
        "result = predict_weather(-52.2391, 113.889, 100, [0.5, 0.8, 1.2], temperature_kmeans, temperature_clusters)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOvqqhi9QlaQ",
        "outputId": "73735096-3f32-4a1f-fcc7-a10c2d1b280e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Temperature Cluster': 1, 'Wind Speed Cluster': 1, 'Rain Probability Cluster': 1, 'Moisture Cluster': 1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def predict_val(longitude, latitude, day):\n",
        "    normalized_coords = scaler_coords.transform([[longitude, latitude]])\n",
        "    normalized_day = temperature_day_scaler.transform([[day]])[0][0]  )\n",
        "    input_features = np.hstack((normalized_coords, [[normalized_day]]))\n",
        "\n",
        "    with open(os.path.join(output_directory, 'temperature.pkl'), 'rb') as file:\n",
        "        temp_model = pickle.load(file)\n",
        "    with open(os.path.join(output_directory, 'wind_speed.pkl'), 'rb') as file:\n",
        "        wind_model = pickle.load(file)\n",
        "    with open(os.path.join(output_directory, 'rain_probability.pkl'), 'rb') as file:\n",
        "        rain_model = pickle.load(file)\n",
        "    with open(os.path.join(output_directory, 'moisture.pkl'), 'rb') as file:\n",
        "        moisture_model = pickle.load(file)\n",
        "\n",
        "    temp_cluster = temp_model.predict(input_features)[0]\n",
        "    wind_cluster = wind_model.predict(input_features)[0]\n",
        "    rain_cluster = rain_model.predict(input_features)[0]\n",
        "    moisture_cluster = moisture_model.predict(input_features)[0]\n",
        "\n",
        "    return {\n",
        "        'Temperature Cluster': temp_cluster,\n",
        "        'Wind Speed Cluster': wind_cluster,\n",
        "        'Rain Probability Cluster': rain_cluster,\n",
        "        'Moisture Cluster': moisture_cluster\n",
        "    }\n",
        "\n",
        "\n",
        "print(predict_val(-52.2391,113.889, 120))  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
